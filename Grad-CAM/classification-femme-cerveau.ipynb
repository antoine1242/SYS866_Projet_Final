{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "np.random.seed(666)\n",
    "\n",
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open('D:/Documents/Grad-CAM/oasis_cross-sectional_labels.csv','r')\n",
    "\n",
    "ligne= file.readlines()\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "noms = []\n",
    "alzheimer = []\n",
    "homme_alz=[]\n",
    "homme_saint=[]\n",
    "femme_alz=[]\n",
    "femme_saint=[]\n",
    "\n",
    "for i in range (1,len(ligne)):\n",
    "    li=str(ligne[i]).rstrip('\\n')\n",
    "    liste=li.split(',')\n",
    "    #print(liste)\n",
    "    if liste[1]== 'F':\n",
    "        \n",
    "        if liste[7] != \"\":\n",
    "            noms.append(liste[0])\n",
    "            if float(liste[7]) <=0.5:\n",
    "                femme_saint.append(liste[0])\n",
    "            else:\n",
    "                femme_alz.append(liste[0])\n",
    "            \n",
    "\n",
    "print(len(femme_alz))\n",
    "print(len(femme_saint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "a='4'\n",
    "print(float(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OAS1_0028_MR1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femme_alz[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil \n",
    "\n",
    "src='/Users/eiser/Desktop/'+femme_alz[1]+'.jpg'\n",
    "os.path.isfile(src)==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "femme_alz_train=femme_alz[:14]\n",
    "femme_alz_test=femme_alz[14:]\n",
    "femme_saint_train=femme_saint[:100]\n",
    "femme_saint_test=femme_saint[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Documents/Grad-CAM/oasis/femme/train/snt/OAS1_0003_MR1_mpr_nn_anon_111_t88_masked_gfcalzheimer.x77.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fc12d0dcf8b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdst1\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\antoine\\appdata\\local\\programs\\python\\python37\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Documents/Grad-CAM/oasis/femme/train/snt/OAS1_0003_MR1_mpr_nn_anon_111_t88_masked_gfcalzheimer.x77.jpg'"
     ]
    }
   ],
   "source": [
    "src1= 'D:/Documents/Grad-CAM/oasis_brain_no_nn_slices/X/Alzheimer/'\n",
    "dst1='D:/Documents/Grad-CAM/oasis/femme/train/snt/'\n",
    "for i in femme_saint_train:\n",
    "    \n",
    "    \n",
    "    \n",
    "    fname = i + '_mpr_nn_anon_111_t88_masked_gfcalzheimer.x77.jpg'\n",
    "    src=src1+fname\n",
    "    dst=dst1+ fname\n",
    "    if os.path.isfile(src)==True:\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = (176, 208)\n",
    "batch_size = 32\n",
    "train_dir='/Users/eiser/Desktop/oasis/femme/train/'\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_dir='/Users/eiser/Desktop/oasis/femme/test/'\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eiser\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model =models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3),activation='relu', input_shape=(176,208,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation ='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation ='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation ='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(include_top=False, input_shape=(176,208,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(conv_base)\n",
    "#model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 5, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5, 6, 512)         262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5, 6, 1)           513       \n",
      "=================================================================\n",
      "Total params: 14,977,857\n",
      "Trainable params: 14,977,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eiser\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers \n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eiser\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 14s 700ms/step - loss: 0.7359 - acc: 0.6375\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 5s 229ms/step - loss: 0.6548 - acc: 0.6500\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 0.6688 - acc: 0.6250\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 0.6334 - acc: 0.6675\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 5s 236ms/step - loss: 0.6479 - acc: 0.6575\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.6447 - acc: 0.6750\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 5s 245ms/step - loss: 0.5462 - acc: 0.7200\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 5s 249ms/step - loss: 0.1042 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 5s 248ms/step - loss: 4.7188e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 5s 248ms/step - loss: 5.0032e-05 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history= model.fit_generator(training_set,steps_per_epoch=20, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc= model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5789473652839661"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path='/Users/eiser/Desktop/oasis/femme/test/alz/OAS1_0425_MR1_mpr_nn_anon_111_t88_masked_gfcalzheimer.x77.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "img= image.load_img(img_path, target_size=(176,208,3))\n",
    "\n",
    "x= image.img_to_array(img)\n",
    "\n",
    "x= np.expand_dims(x, axis=0)\n",
    "\n",
    "x= preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 5, 6, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-3ff73a1c94e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m                          \u001b[1;34m'a batch of predictions '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                          \u001b[1;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                          'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[0;32m    223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         fpath = keras_utils.get_file(\n",
      "\u001b[1;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 5, 6, 1)"
     ]
    }
   ],
   "source": [
    "decode_predictions(preds,top=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "sortie= conv_base.output[:, 1]\n",
    "\n",
    "last_conv_layer = conv_base.get_layer('block5_conv3')\n",
    "\n",
    "grads = K.gradients(sortie, last_conv_layer.output)[0]\n",
    "\n",
    "pooled_grads = K.mean(grads, axis=(0,1,2))\n",
    "\n",
    "iterate = K.function([conv_base.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
    "    \n",
    "    \n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x171fde54320>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 340.364x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(heatmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "heatmap= cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "\n",
    "cv2.imwrite('/Users/eiser/Desktop/cerveau_cam.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
