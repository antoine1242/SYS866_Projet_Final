{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "np.random.seed(666)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séparation des images en ensembles d'entraînement, validation et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil \n",
    "\n",
    "original_dataset_dir= 'D:/Documents/SYS866_Projet_Final/Grad-CAM/HCP_SYS866_2020/'\n",
    "\n",
    "base_dir='D:/Documents/SYS866_Projet_Final/Grad-CAM/cerveaux/'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "    \n",
    "train_dir=os.path.join(base_dir,'train/')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "    \n",
    "validation_dir=os.path.join(base_dir,'validation/')\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.mkdir(validation_dir)\n",
    "    \n",
    "test_dir=os.path.join(base_dir,'test/')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_homme_dir=os.path.join(train_dir,'homme')\n",
    "if not os.path.exists(train_homme_dir):\n",
    "    os.mkdir(train_homme_dir)\n",
    "\n",
    "train_femme_dir = os.path.join(train_dir, 'femme')\n",
    "if not os.path.exists(train_femme_dir):\n",
    "    os.mkdir(train_femme_dir)\n",
    "    \n",
    "validation_homme_dir=os.path.join(validation_dir,'homme')\n",
    "if not os.path.exists(validation_homme_dir):\n",
    "    os.mkdir(validation_homme_dir)\n",
    "\n",
    "validation_femme_dir = os.path.join(validation_dir, 'femme')\n",
    "if not os.path.exists(validation_femme_dir):\n",
    "    os.mkdir(validation_femme_dir)\n",
    "    \n",
    "test_homme_dir=os.path.join(test_dir,'homme')\n",
    "if not os.path.exists(test_homme_dir):\n",
    "    os.mkdir(test_homme_dir)\n",
    "\n",
    "test_femme_dir = os.path.join(test_dir, 'femme')\n",
    "if not os.path.exists(test_femme_dir):\n",
    "    os.mkdir(test_femme_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open('D:/Documents/SYS866_Projet_Final/Grad-CAM/labels.csv','r')\n",
    "\n",
    "ligne= file.readlines()\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom=[]\n",
    "sexe=[]\n",
    "\n",
    "\n",
    "for i in range (2,len(ligne)):\n",
    "    \n",
    "    li=str(ligne[i]).rstrip('\\n')\n",
    "    liste=li.split(',')\n",
    "    nom.append(liste[0])\n",
    "    sexe.append(liste[8])\n",
    "    \n",
    "print(len(nom))\n",
    "print(len(sexe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout d'images au dossier d'entrainement\n",
    "for i in range(0, 1000):\n",
    "    fname='img'+nom[i]+'_T1w.png'\n",
    "    src= os.path.join(original_dataset_dir, fname)\n",
    "    if os.path.isfile(src)==True:\n",
    "        if sexe[i]=='1':\n",
    "            src= os.path.join(original_dataset_dir, fname)\n",
    "            dst=os.path.join(train_homme_dir, fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "        else:\n",
    "            src= os.path.join(original_dataset_dir, fname)\n",
    "            dst=os.path.join(train_femme_dir, fname)\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout d'images au dossier de validation\n",
    "for i in range(1000, 1100):\n",
    "    fname='img'+nom[i]+'_T1w.png'\n",
    "    src= os.path.join(original_dataset_dir, fname)\n",
    "    if os.path.isfile(src)==True:\n",
    "        if sexe[i]=='1':\n",
    "            src= os.path.join(original_dataset_dir, fname)\n",
    "            dst=os.path.join(validation_homme_dir, fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "        else:\n",
    "            src= os.path.join(original_dataset_dir, fname)\n",
    "            dst=os.path.join(validation_femme_dir, fname)\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout d'images au dossier de test\n",
    "for i in range(1100, 1205):\n",
    "    fname='img'+nom[i]+'_T1w.png'\n",
    "    src= os.path.join(original_dataset_dir, fname)\n",
    "    if os.path.isfile(src)==True:\n",
    "        if sexe[i]=='1':\n",
    "            src= os.path.join(original_dataset_dir, fname)\n",
    "            dst=os.path.join(test_homme_dir, fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "        else:\n",
    "            src= os.path.join(original_dataset_dir, fname)\n",
    "            dst=os.path.join(test_femme_dir, fname)\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.10,\n",
    "        brightness_range=[0.5,1.5],\n",
    "        #horizontal_flip=True,\n",
    "        rotation_range=5)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_size = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    \"cerveaux/train\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = validation_datagen.flow_from_directory(\n",
    "    \"cerveaux/validation\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    \"cerveaux/test\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du modèle et entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3),activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation ='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation ='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x = training_set, validation_data=validation_set, shuffle=True, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traçage des graphiques d'entraînement et ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc= history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss= history.history['loss']\n",
    "val_loss= history.history['val_loss']\n",
    "\n",
    "epochs= range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='entrainement')\n",
    "plt.plot(epochs, val_acc,'b', label='validation')\n",
    "plt.title('Exactitude pendant l\\'entrainement et la validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='entrainement')\n",
    "plt.plot(epochs, val_loss, 'b', label='validation')\n",
    "plt.title('Perte pendant l\\'entrainement et la validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_tp, test_fp, test_tn, test_fn, test_acc, test_prec, test_recall, test_auc = model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_loss, test_tp, test_fp, test_tn, test_fn, test_acc, test_prec, test_recall, test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('./cerveaux/test/homme/img999517_T1w.png', target_size = (150, 150))\n",
    "test_image = image.img_to_array(test_image)/255.\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "prediction = model.predict_on_batch(test_image)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def test_image(IMAGE_PATH):\n",
    "    test_image = image.load_img(IMAGE_PATH, target_size = (150, 150))\n",
    "    test_image = image.img_to_array(test_image)/255.\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "    prediction = model.predict_on_batch(test_image)\n",
    "    \n",
    "    if prediction[0,0] < prediction[0,1]:\n",
    "        print(IMAGE_PATH.split(\"/\")[-1])\n",
    "        print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for filename in os.listdir('./cerveaux/test/femme/'):\n",
    "    \n",
    "    test_image('./cerveaux/test/femme/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_labels = test_set.classes\n",
    "true_labels = []\n",
    "\n",
    "for label in y_true_labels:\n",
    "    true_labels.append(np.array([np.float32(label)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_set)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for x in preds.tolist():\n",
    "    predictions.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(true_labels, predictions)\n",
    "auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.3f}'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Documents/SYS866_Projet_Final/Grad-CAM/models/4_couches_adam_97_62_categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour juste loader le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = keras.models.load_model('D:/Documents/SYS866_Projet_Final/Grad-CAM/models/4_couches_adam_97_62_categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://gist.github.com/RaphaelMeudec/e9a805fa82880876f8d89766f0690b54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(CLASS_INDEX, LAYER_NAME, IMAGE_PATH, MODEL_PATH):\n",
    "    img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(150, 150))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)/255.\n",
    "\n",
    "    model = keras.models.load_model(MODEL_PATH)\n",
    "    \n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(LAYER_NAME).output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.array([img]))\n",
    "        loss = predictions[:, CLASS_INDEX]\n",
    "\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "    gate_f = tf.cast(output > 0, 'float32')\n",
    "    gate_r = tf.cast(grads > 0, 'float32')\n",
    "    guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
    "\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "    cam = np.ones(output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "\n",
    "    cam = cv2.resize(cam.numpy(), (150, 150))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    output_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\n",
    "\n",
    "    \n",
    "    name = IMAGE_PATH.split(\"/\")[-1].split(\".\")[0]\n",
    "    true_class = IMAGE_PATH.split(\"/\")[-2]\n",
    "    cv2.imwrite('./pictures/' + name + '_' + str(CLASS_INDEX) + '_' + true_class + '.png', output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOMME_CLASS_INDEX = 1\n",
    "FEMME_CLASS_INDEX = 0\n",
    "\n",
    "MODEL_PATH = \"D:/Documents/SYS866_Projet_Final/Grad-CAM/models/4_couches_adam_97_62_categorical\"\n",
    "image_paths = ['./cerveaux/test/femme/img915604_T1w.png',\n",
    "               './cerveaux/test/femme/img920479_T1w.png',\n",
    "               './cerveaux/test/femme/img925619_T1w.png',\n",
    "               './cerveaux/test/femme/img927528_T1w.png',\n",
    "               './cerveaux/test/femme/img975176_T1w.png',\n",
    "               './cerveaux/test/femme/img948145_T1w.png',\n",
    "               './cerveaux/test/femme/img915604_T1w_flipped.png',\n",
    "               './cerveaux/test/femme/img920479_T1w_flipped.png']\n",
    "CLASS_INDEX = FEMME_CLASS_INDEX\n",
    "LAYER_NAME = 'conv2d_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for IMAGE_PATH in image_paths:\n",
    "    grad_cam(CLASS_INDEX, LAYER_NAME, IMAGE_PATH, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps \n",
    "\n",
    "im1 = Image.open('./cerveaux/test/femme/img915604_T1w.png')\n",
    "im2 = Image.open('./cerveaux/test/femme/img920479_T1w.png')\n",
    "\n",
    "im_mirror1 = ImageOps.mirror(im1)\n",
    "im_mirror2 = ImageOps.mirror(im2)\n",
    "\n",
    "im_mirror1.save('./cerveaux/test/femme/img915604_T1w_mirror.png', quality=100)\n",
    "im_mirror2.save('./cerveaux/test/femme/img920479_T1w_mirror.png', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
